{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import time\n",
    "import math\n",
    "import pandas as pd\n",
    "from numba import cuda, float32, float64\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "import random\n",
    "from numba import cuda\n",
    "random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readData(file):\n",
    "    file=open(file, 'r')\n",
    "    reader=csv.reader(file)\n",
    "    data= []\n",
    "    for line in reader:\n",
    "        data.append(line)\n",
    "    data=np.array(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Computes wT*x[i] ( the predicted value for datum)\n",
    "def H(x,w,i):\n",
    "    sum=0\n",
    "    for j in range(len(x[0])):\n",
    "        sum+=x[i][j]*w[j]\n",
    "    return sum "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_prop(x, weights):\n",
    "    weights2=weights[n_inputs*n_hidden:]\n",
    "    z3=0\n",
    "    #Pass data from the initial layer to the hidden neurons\n",
    "    for j in range(0,n_hidden-1):\n",
    "        weights1=weights[n_inputs*j:n_inputs*(j+1)]\n",
    "        result=0\n",
    "        for k in range(0,n_inputs):\n",
    "            result+=(x[k]*weights1[k])\n",
    "            #result+=0.1\n",
    "        #Activation function ReLu\n",
    "        #result=max(0, result)\n",
    "        #We can add what each hidden neuron contributes to the output layer\n",
    "        z3+=result*weights2[j]\n",
    "    #We add the bias\n",
    "    z3+=weights2[n_hidden-1]\n",
    "    return z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for calculating the error\n",
    "def forward_propagation_Error(x,y,w):\n",
    "    E=0\n",
    "    for i in range(0, len(x)):\n",
    "        wx=0\n",
    "        wx=forward_prop(x[i], w)\n",
    "        E+=((wx-y[i][0])**2)\n",
    "    E=E/len(x)\n",
    "    return E"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Particle:\n",
    "    def __init__(self, position, initial_fitness):\n",
    "         # particles position\n",
    "        self.particle_position = position\n",
    "        #initial value of the particle (infinity or minus infinity,\n",
    "        #depending on whether we want to maximize or minimize)\n",
    "        self.fitness_particle_position = initial_fitness\n",
    "        # best position of the particle\n",
    "        self.local_best_particle_position = []  \n",
    "        #best initial value of the particle (infinity or minus infinity, \n",
    "        #depending on whether we want to maximize or minimize)\n",
    "        self.fitness_local_best_particle_position = initial_fitness  \n",
    "        # particle's velocity\n",
    "        self.particle_velocity = []  \n",
    "        for i in range(0,num_dimensions):\n",
    "            #we generate the initial velocity randomly\n",
    "            self.particle_velocity.append(random.uniform(-vMax, vMax))  \n",
    " \n",
    "    def evaluate(self, x, y, mm):\n",
    "        self.fitness_particle_position = forward_propagation_Error(x, y, self.particle_position)\n",
    "        if mm == -1:\n",
    "            if self.fitness_particle_position < self.fitness_local_best_particle_position:\n",
    "                # We update the best local position\n",
    "                self.local_best_particle_position = self.particle_position  \n",
    "                # We update the best local value \n",
    "                self.fitness_local_best_particle_position = self.fitness_particle_position          \n",
    "        if mm == 1:\n",
    "            if self.fitness_particle_position > self.fitness_local_best_particle_position:\n",
    "                 # We update the best local position\n",
    "                self.local_best_particle_position = self.particle_position  \n",
    "                # We update the best local value \n",
    "                self.fitness_local_best_particle_position = self.fitness_particle_position   \n",
    "    def update_velocity(self, global_best_particle_position, w, Vmax, c1=2.8, c2=1.3):\n",
    "        for i in range(0,num_dimensions):\n",
    "            r1 = random.random()\n",
    "            r2 = random.random()\n",
    "            #We calculate the new velocity\n",
    "            self.particle_velocity[i] = w * self.particle_velocity[i] + c1 * r1 * (self.local_best_particle_position[i] - self.particle_position[i]) + c2 * r2 * (global_best_particle_position[i] - self.particle_position[i])\n",
    "            \n",
    "            #We limit the maxmum velocity\n",
    "            if(self.particle_velocity[i]>Vmax):\n",
    "                self.particle_velocity[i]=Vmax\n",
    "            if(self.particle_velocity[i]<-Vmax):\n",
    "                self.particle_velocity[i]=-Vmax\n",
    " \n",
    "    def update_position(self, bounds):\n",
    "        for i in range(0,num_dimensions):\n",
    "            self.particle_position[i] = self.particle_position[i] + self.particle_velocity[i]\n",
    " \n",
    "            #if it reaches the edges, it stays within, it does not exceed the limits\n",
    "            if self.particle_position[i] > bounds[1]:\n",
    "                self.particle_position[i] = bounds[1]\n",
    "            if self.particle_position[i] < bounds[0]:\n",
    "                self.particle_position[i] = bounds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv('Bias_correction_ucl.csv')\n",
    "\n",
    "# # Defining all the conditions inside a function\n",
    "# def condition(x):\n",
    "#     if x>=10 and x<=29:\n",
    "#         return \"0\"\n",
    "# #     elif x>=21 and x<=28:\n",
    "# #         return \"Warm\"\n",
    "#     else:\n",
    "#         return '1'\n",
    " \n",
    "# # Applying the conditions\n",
    "# df['Next_Tmax_Classification'] = df['Next_Tmax'].apply(condition)\n",
    " \n",
    "# print(df)\n",
    "# df.to_csv('Bias_correction_ucl_Out.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PS0 parameters\n",
    "num_iters=600\n",
    "num_particles=50\n",
    "c1=1.0\n",
    "c2=1.2\n",
    "factor=10\n",
    "Fi=c1+c2\n",
    "Xi=2/(abs(2-Fi-math.sqrt(abs(Fi**2-4*Fi))))\n",
    "data=readData('housing_Out.csv')\n",
    "#print('Data prior removing',data)\n",
    "#We remove the first row of names and the last column\n",
    "data=data[1:500,2:10]\n",
    "#print('Data after removing',data)\n",
    "# We preprocess the data\n",
    "datosPandas=pd.DataFrame(data)\n",
    "#We refill the missing data with the averagge\n",
    "datosPandas.replace('?',np.NaN,inplace=True)\n",
    "imp=SimpleImputer(missing_values=np.NaN)\n",
    "datos=imp.fit_transform(datosPandas)\n",
    "#print('Datos after pre-processing',datos)\n",
    "# Shuffle the data list above\n",
    "np.random.shuffle(datos)\n",
    "#Percentage of training (in this sample, 50%) and percentage of testing (25%)\n",
    "p_train = 0.7\n",
    "#Number of elements in the training and test datasets\n",
    "len_train=int((len(datos))*p_train)\n",
    "datos_train=datos[:len_train,:]\n",
    "datos_test=datos[(len_train):,:]\n",
    "#We separate the data \"x\" from the \"y\" (the data \"y\" is in the last column)\n",
    "num_atrib=int(len(datos[0]))-1\n",
    "x_train=datos_train[:,:num_atrib]\n",
    "y_train=datos_train[:,num_atrib]\n",
    "x_test=datos_test[:,:num_atrib]\n",
    "y_test=datos_test[:,num_atrib]\n",
    "# datosPandas.head()\n",
    "#print('vector x_train ',x_train)\n",
    "#print('vector y_train ',y_train)\n",
    "# df = pd.DataFrame(data)\n",
    "# print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Data re-scaling\n",
    "y_train=np.reshape(y_train, (-1,1))\n",
    "y_train.reshape(-1,1)\n",
    "y_test=np.reshape(y_test, (-1,1))\n",
    "scaler_x = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "#\n",
    "scaler_x.fit(x_train)\n",
    "x_train=scaler_x.transform(x_train)\n",
    "x_test=scaler_x.transform(x_test)\n",
    "#\n",
    "scaler_y.fit(y_train)\n",
    "y_train=scaler_y.transform(y_train)\n",
    "y_test=scaler_y.transform(y_test)\n",
    "#print('vector x_train scaled ',x_train)\n",
    "#print('vector y_train scaled',y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Neural network parameters (as function of the input)\n",
    "n_inputs=x_train[0].size\n",
    "n_hidden=math.floor(len(x_train)/(factor*(n_inputs+1)))+1\n",
    "#We calculate the number of weights necessary to carry out the computation\n",
    "num_weights=(n_inputs*n_hidden)+n_hidden\n",
    "bound0=float(max(y_train))#upper limit\n",
    "bound1=-bound0 #lower limit\n",
    "vMax=bound0*0.6\n",
    "weights=[]\n",
    "for i in range(0,num_particles):\n",
    "        for j in range(0, num_weights):\n",
    "            weights.append(random.uniform(-1, 1))\n",
    "#print('total number of weights ', len(weights))\n",
    "#print('Initial weights values', weights )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neural_Network:\n",
    "    # the parameters are the data, the number of neurons of the input layer, \n",
    "    # the number of neurons of the hidden layer and \n",
    "    # the number of neurons of the output layer\n",
    "    def __init__(self, x, y, n_inputs, n_hidden, weights, num_weights):\n",
    "        self.input=x\n",
    "        self.y=y\n",
    "        \n",
    "        self.weights=weights\n",
    "        self.num_weights=num_weights\n",
    "        \n",
    "    def train_PSO(self):\n",
    "        best_position, fitness=PSO_Neural_Network(self.input, self.y,self.weights, self.num_weights,[bound1,bound0], -1, num_particles, 100, 0.9, 0.1, vMax)\n",
    "        self.weights=best_position\n",
    "        return fitness\n",
    "    \n",
    "    def predict(self, x_test):\n",
    "        return forward_prop(x_test, self.weights)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PSO parallel\n",
    "@cuda.jit\n",
    "#def PSO_GPU(x, y):\n",
    "def PSO_GPU(x, y, particle_positions, particle_velocity, personal_best_particle_position,fitness_personal_best_particle_position, local_best_particle_position, fitness_local_best_particle_position,pool, c1, c2, Vmax, bound0, bound1):\n",
    "  \n",
    "    particle= cuda.blockIdx.x #We found the particle that corresponds to the block where the thread is\n",
    "    nx=cuda.threadIdx.x #Finds the neurons of the hidden layer that this thread is going to calculate \n",
    "    #in this thread. Thread '0' does the rest of the particle calculations\n",
    "   \n",
    "    #We initialize the vectors in a shared-memory array (common to the block == to the particle)\n",
    "    z2=cuda.shared.array(shape=n_hidden, dtype=float32)\n",
    "\n",
    "    for iters in range(0, num_iters):\n",
    "        #We take particle's position corresponding to the thread\n",
    "        position=particle_positions[num_weights*particle: num_weights*(particle+1)]\n",
    "\n",
    "        #We do forward propagation\n",
    "        fitness_position=0\n",
    "        weights2=position[n_inputs*n_hidden:]\n",
    "        for i in range(0, len(x)):\n",
    "            j=nx\n",
    "            while(j<n_hidden):\n",
    "                #Pass from the init layer to the hidden layer\n",
    "                hidden_result=0\n",
    "                weights1=position[n_inputs*j:n_inputs*(j+1)]\n",
    "                for k in range(0,n_inputs-1):\n",
    "                    hidden_result+=(x[i][k]*weights1[k])\n",
    "                hidden_result+=weights1[n_inputs-1] #We add the bias\n",
    "                #Function ReLu (activation of)\n",
    "                hidden_result=max(0, hidden_result)\n",
    "                #We save the value in the vector z2, to add it when the total value \n",
    "                #is calculated in the output layer\n",
    "                z2[j]=hidden_result*weights2[j]\n",
    "                j=j+threadsperblock\n",
    "   \n",
    "            # Thread synchronization\n",
    "            cuda.syncthreads()\n",
    "           \n",
    "            #Thread '0' gathers the results of other threads\n",
    "            if(nx==0):\n",
    "                result=0\n",
    "                for h in range (0, n_hidden):\n",
    "                    result+=z2[h]\n",
    "                fitness_position+=float((y[i][0]-result)**2)\n",
    "            # Thread synchronization\n",
    "            cuda.syncthreads()\n",
    "            \n",
    "        if(nx==0):\n",
    "            #We update the best personal position\n",
    "            fitness_position=fitness_position/len(x)\n",
    "            if fitness_position < fitness_personal_best_particle_position[particle]:\n",
    "                for i in range(0, num_weights):\n",
    "                    personal_best_particle_position[(num_weights*particle)+i] = particle_positions[num_weights*particle+i]  # we update the best personal position\n",
    "                # we update the best personal value\n",
    "                fitness_personal_best_particle_position[particle] = fitness_position \n",
    "       \n",
    "        # We synchronize the threads\n",
    "        cuda.syncthreads()\n",
    "       \n",
    "        if(nx==0):\n",
    "            #Best local position updating\n",
    "            if fitness_personal_best_particle_position[particle]< fitness_local_best_particle_position[particle]:\n",
    "                for i in range(0, num_weights):\n",
    "                    local_best_particle_position[num_weights*particle+i] = personal_best_particle_position[(num_weights*particle)+i]\n",
    "                fitness_local_best_particle_position[particle] = fitness_personal_best_particle_position[particle]\n",
    "           \n",
    "            if fitness_personal_best_particle_position[int(math.fmod((num_particles+particle-1), num_particles))] < fitness_local_best_particle_position[particle]:\n",
    "                for i in range(0, num_weights):\n",
    "                    local_best_particle_position[num_weights*(particle)+i] = particle_positions[num_weights*(int(math.fmod((num_particles+particle-1), num_particles)))+i]\n",
    "                fitness_local_best_particle_position[particle] = fitness_personal_best_particle_position[int(math.fmod((num_particles+particle-1), num_particles))]\n",
    "           \n",
    "               \n",
    "            if fitness_personal_best_particle_position[int(math.fmod((num_particles+particle+1), num_particles))] < fitness_local_best_particle_position[particle]:\n",
    "                for i in range(0, num_weights):\n",
    "                    local_best_particle_position[num_weights*(particle)+i] = particle_positions[num_weights*(int(math.fmod((num_particles+particle+1), num_particles)))+i]\n",
    "                fitness_local_best_particle_position[particle] = fitness_personal_best_particle_position[int(math.fmod((num_particles+particle+1), num_particles))]\n",
    "           \n",
    "        # Thread synchronization\n",
    "        cuda.syncthreads()\n",
    "        \n",
    "        #We choose numbers from the random numbers repository\n",
    "        r1=pool[2*num_weights*num_particles+particle+iters]\n",
    "        r2=pool[2*num_weights*num_particles-particle-iters]\n",
    "       \n",
    "        i=nx\n",
    "        #We update each particle's velocity\n",
    "        while i<num_weights:\n",
    "            #We calculate the new velocity\n",
    "            particle_velocity[num_weights*particle+i] = Xi*( particle_velocity[num_weights*particle+i] + c1 * r1 * (personal_best_particle_position[num_weights*particle+i] - particle_positions[num_weights*particle+i]) + c2 * r2 * (local_best_particle_position[num_weights*particle+i] - particle_positions[num_weights*particle+i]))\n",
    "            #We limit speed to maximum speed\n",
    "            if particle_velocity[num_weights*particle+i]>Vmax :\n",
    "                particle_velocity[num_weights*particle+i]=Vmax\n",
    "            if particle_velocity[num_weights*particle+i]<(Vmax*(-1)):\n",
    "                particle_velocity[num_weights*particle+i]=(Vmax*(-1))\n",
    "            i+=threadsperblock\n",
    "       \n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()      \n",
    "        i=nx\n",
    "        #We update each particle's position\n",
    "        while i<num_weights:\n",
    "            particle_positions[num_weights*particle+i] = particle_positions[num_weights*particle+i] + particle_velocity[num_weights*particle+i]\n",
    "            #if it reaches and edge, it stays in there, it does not trespasses it\n",
    "            if particle_positions[num_weights*particle+i] > bound0:\n",
    "                particle_positions[num_weights*particle+i] = bound0\n",
    "            if particle_positions[num_weights*particle+i] < bound1:\n",
    "                particle_positions[num_weights*particle+i] = bound1\n",
    "            i+=threadsperblock\n",
    "           \n",
    "        # Wait until all threads finish computing\n",
    "        cuda.syncthreads()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coresPerSM():\n",
    "    cc_cores_per_SM_dict = {\n",
    "    (2,0) : 32,\n",
    "    (2,1) : 48,\n",
    "    (3,0) : 192,\n",
    "    (3,5) : 192,\n",
    "    (3,7) : 192,\n",
    "    (5,0) : 128,\n",
    "    (5,2) : 128,\n",
    "    (6,0) : 64,\n",
    "    (6,1) : 128,\n",
    "    (7,0) : 64,\n",
    "    (7,5) : 64,\n",
    "    (8,0) : 64,\n",
    "    (8,6) : 128\n",
    "    }\n",
    "    # the above dictionary should result in a value of \"None\" if a cc match \n",
    "    # is not found.  The dictionary needs to be extended as new devices become\n",
    "    # available, and currently does not account for all Jetson devices\n",
    "    device = cuda.get_current_device()\n",
    "    #my_cc = getattr(device, 'COMPUTE_CAPABILITY')\n",
    "    my_cc=(6,1)\n",
    "    cores_per_sm = cc_cores_per_SM_dict.get(my_cc)\n",
    "    return cores_per_sm\n",
    "#device = cuda.get_current_device()\n",
    "threadsperblock =  coresPerSM()\n",
    "blockspergrid=num_particles\n",
    "#print('device, num weights, threads per block, blocks, c1, c2, vMax, bound0, bound1 ->',getattr(device, 'MULTIPROCESSOR_COUNT'),num_weights,threadsperblock,blockspergrid,c1, c2, vMax, bound0, bound1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded in GPU correctly!\n"
     ]
    }
   ],
   "source": [
    "#We generate one pool of random numbers and initial data\n",
    "pool=[]\n",
    "fitness_personal_best_particle_position=[]\n",
    "fitness_local_best_particle_position=[]\n",
    "for i in range(0,num_particles):\n",
    "        for j in range(0, num_weights*3):\n",
    "            pool.append(random.uniform(bound1, bound0))\n",
    "        fitness_local_best_particle_position.append(float(\"inf\"))\n",
    "        fitness_personal_best_particle_position.append(float(\"inf\"))\n",
    "#We load data to the gpu\n",
    "x_global_mem=cuda.to_device(np.ascontiguousarray(x_train))\n",
    "y_global_mem=cuda.to_device(np.ascontiguousarray(y_train))\n",
    "fitness_personal_best_particle_position_global_mem=cuda.to_device(np.asarray(fitness_personal_best_particle_position))\n",
    "personal_best_particle_position=cuda.to_device(np.zeros(num_weights*num_particles))\n",
    "local_best_particle_position=cuda.to_device(np.zeros(num_weights*num_particles))\n",
    "fitness_local_best_particle_position_global_mem=cuda.to_device(np.ascontiguousarray(fitness_local_best_particle_position))\n",
    "pool_global_mem=cuda.to_device(np.ascontiguousarray(pool))\n",
    "\n",
    "#We initiate positions and velocities of particles by taking data from the pool of random numbers\n",
    "particles_positions=pool_global_mem[0:num_weights*num_particles]\n",
    "particles_velocity=pool_global_mem[num_weights*num_particles:2*num_weights*num_particles]\n",
    "print(\"Data loaded in GPU correctly!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name = b'GeForce GTX 1050 Ti'\n",
      "maxThreadsPerBlock = 1024\n",
      "maxBlockDimX = 1024\n",
      "maxBlockDimY = 1024\n",
      "maxBlockDimZ = 64\n",
      "maxGridDimX = 2147483647\n",
      "maxGridDimY = 65535\n",
      "maxGridDimZ = 65535\n",
      "maxSharedMemoryPerBlock = 49152\n",
      "asyncEngineCount = 5\n",
      "canMapHostMemory = 1\n",
      "multiProcessorCount = 6\n",
      "warpSize = 32\n",
      "unifiedAddressing = 1\n",
      "pciBusID = 1\n",
      "pciDeviceID = 0\n"
     ]
    }
   ],
   "source": [
    "from numba import cuda\n",
    "gpu = cuda.get_current_device()\n",
    "print(\"name = %s\" % gpu.name)\n",
    "print(\"maxThreadsPerBlock = %s\" % str(gpu.MAX_THREADS_PER_BLOCK))\n",
    "print(\"maxBlockDimX = %s\" % str(gpu.MAX_BLOCK_DIM_X))\n",
    "print(\"maxBlockDimY = %s\" % str(gpu.MAX_BLOCK_DIM_Y))\n",
    "print(\"maxBlockDimZ = %s\" % str(gpu.MAX_BLOCK_DIM_Z))\n",
    "print(\"maxGridDimX = %s\" % str(gpu.MAX_GRID_DIM_X))\n",
    "print(\"maxGridDimY = %s\" % str(gpu.MAX_GRID_DIM_Y))\n",
    "print(\"maxGridDimZ = %s\" % str(gpu.MAX_GRID_DIM_Z))\n",
    "print(\"maxSharedMemoryPerBlock = %s\" % \n",
    "str(gpu.MAX_SHARED_MEMORY_PER_BLOCK))\n",
    "print(\"asyncEngineCount = %s\" % str(gpu.ASYNC_ENGINE_COUNT))\n",
    "print(\"canMapHostMemory = %s\" % str(gpu.CAN_MAP_HOST_MEMORY))\n",
    "print(\"multiProcessorCount = %s\" % str(gpu.MULTIPROCESSOR_COUNT))\n",
    "print(\"warpSize = %s\" % str(gpu.WARP_SIZE))\n",
    "print(\"unifiedAddressing = %s\" % str(gpu.UNIFIED_ADDRESSING))\n",
    "print(\"pciBusID = %s\" % str(gpu.PCI_BUS_ID))\n",
    "print(\"pciDeviceID = %s\" % str(gpu.PCI_DEVICE_ID))\n",
    "#name = b'NVIDIA GeForce 940MX'\n",
    "#maxThreadsPerBlock = 1024\n",
    "#maxBlockDimX = 1024\n",
    "#maxBlockDimY = 1024\n",
    "#maxBlockDimZ = 64\n",
    "#maxGridDimX = 2147483647\n",
    "#maxGridDimY = 65535\n",
    "#maxGridDimZ = 65535\n",
    "#maxSharedMemoryPerBlock = 49152\n",
    "#asyncEngineCount = 4\n",
    "#canMapHostMemory = 1\n",
    "#multiProcessorCount = 3\n",
    "#warpSize = 32\n",
    "#unifiedAddressing = 1\n",
    "#pciBusID = 1\n",
    "#pciDeviceID = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time(s):  1.7427537441253662\n"
     ]
    }
   ],
   "source": [
    "#And now it's time to launch the computation in parallel!!!!\n",
    "start = time.time()\n",
    "cuda.profile_start()\n",
    "\n",
    "PSO_GPU[blockspergrid, threadsperblock](x_global_mem, y_global_mem,particles_positions, particles_velocity, personal_best_particle_position,fitness_personal_best_particle_position_global_mem, local_best_particle_position,fitness_local_best_particle_position_global_mem, pool_global_mem,c1, c2, vMax, bound0, bound1)\n",
    "\n",
    "local_best_particle_position_host=local_best_particle_position.copy_to_host()\n",
    "fitness_local_best_particle_position=fitness_local_best_particle_position_global_mem.copy_to_host()\n",
    "cuda.profile_stop()\n",
    "end = time.time()\n",
    "time=end - start\n",
    "print(\"Execution time(s): \", time)\n",
    "#Execution time(s):  3.7838525772094727"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of iterations of PSO = 600\n",
      "Running time(s):  1.7317521572113037\n",
      "Ein: 0.02857326737382096\n",
      "Eout: 0.6553971893000057\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "global_best_particle_position=[]\n",
    "fitness_global_best_particle_position=float(\"inf\")\n",
    "for i in range(0, num_particles):\n",
    "    if(fitness_local_best_particle_position[i]<fitness_global_best_particle_position):\n",
    "        global_best_particle_position=local_best_particle_position_host[num_weights*i:num_weights*(i+1)]\n",
    "        fitness_global_best_particle_position=fitness_local_best_particle_position[i]\n",
    "\n",
    "#We calculate the transfer time between the host (CPU) and the device (GPU), and we remove it from the calculation\n",
    "start2 = time.time()\n",
    "local_best_particle_position_host=local_best_particle_position.copy_to_host()\n",
    "fitness_local_best_particle_position=fitness_local_best_particle_position_global_mem.copy_to_host()\n",
    "end2 = time.time()\n",
    "time_corr=end - start -(end2-start2)\n",
    "#Error calculation\n",
    "Eout=0\n",
    "Error_Cero=0\n",
    "prediction=np.zeros(len(x_test))\n",
    "for i in range(0, len(x_test)):\n",
    "        prediction[i]=forward_prop(x_test[i], global_best_particle_position)\n",
    "        # mean standard error (MSE), for regression problems\n",
    "        Eout+=float((y_test[i][0]-prediction[i]))**2\n",
    "Eout=Eout/len(x_test)\n",
    "#results\n",
    "print(\"Number of iterations of PSO =\", num_iters)\n",
    "print(\"Running time(s): \", time_corr)\n",
    "print('Ein:', fitness_global_best_particle_position)\n",
    "print('Eout:', Eout)\n",
    "#Number of iterations of PSO = 600\n",
    "#Running time(s):  3.7838525772094727\n",
    "#Ein: 0.03040794978739939\n",
    "#Eout: 0.19263899013255337"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "median_pred_results:  0.0019530351\n",
      "max_pred_results:  0.061390672\n",
      "min_pred_results:  1.6713778e-11\n",
      "median_y_test:  0.194534431315276\n",
      "max_y_test:  1.0\n",
      "min_y_test:  -0.02325575987032591\n",
      "pred_results: \n",
      " [[6.88606815e-04 3.72112445e-05 5.52822603e-03 ... 7.84436427e-03\n",
      "  8.55377689e-03 3.15991677e-02]\n",
      " [1.31117494e-03 1.49670595e-05 4.14519757e-03 ... 6.17789477e-03\n",
      "  6.80918759e-03 3.52426954e-02]\n",
      " [1.98434526e-03 1.48951513e-04 3.14130750e-03 ... 4.93699359e-03\n",
      "  5.50296297e-03 3.84419635e-02]\n",
      " ...\n",
      " [4.78238100e-03 1.35522196e-03 9.88385524e-04 ... 2.08437652e-03\n",
      "  2.45750113e-03 4.86974493e-02]\n",
      " [3.69894109e-03 8.10967933e-04 1.58200599e-03 ... 2.91500799e-03\n",
      "  3.35345580e-03 4.50879149e-02]\n",
      " [1.61358534e-04 3.85679450e-04 7.72476848e-03 ... 1.04258470e-02\n",
      "  1.12413540e-02 2.69691683e-02]]\n"
     ]
    }
   ],
   "source": [
    "# prediction=np.zeros(len(x_test))\n",
    "red_neuronal=Neural_Network(x_train, y_train, n_inputs, n_hidden, weights, num_weights)\n",
    "\n",
    "# red_neuronal.fit(x_train,y_train)\n",
    "pred_results = []\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    y_pred=red_neuronal.predict(x_test[i])\n",
    "    y_pred=(1/len(x_test))*((prediction-y_test[i])**2)\n",
    "    pred_results.append(y_pred)\n",
    "np.hstack(pred_results)\n",
    "pred_results = np.array(pred_results, dtype=np.float32)\n",
    "maxValue_pred_results = np.max(pred_results)\n",
    "minValue_pred_results = np.min(pred_results)\n",
    "median_pred_results = np.median(pred_results)\n",
    "median_y_test = np.median(y_test)\n",
    "maxValue_y_test = np.max(y_test)\n",
    "minValue_y_test = np.min(y_test)\n",
    "print('median_pred_results: ', median_pred_results)\n",
    "print('max_pred_results: ', maxValue_pred_results)\n",
    "print('min_pred_results: ',minValue_pred_results)\n",
    "print('median_y_test: ', median_y_test)\n",
    "print('max_y_test: ',maxValue_y_test)\n",
    "print('min_y_test: ',minValue_y_test)\n",
    "print('pred_results: \\n', pred_results)\n",
    "#median_pred_results:  0.025712231\n",
    "#max_pred_results:  0.049852207\n",
    "#min_pred_results:  0.021009997\n",
    "#median_y_test:  0.20568135072420293\n",
    "#max_y_test:  0.9763614173604153\n",
    "#min_y_test:  0.017045415805873182"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred_classes: \n",
      "  [[0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 1.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n",
      "y_test: \n",
      " [[0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [0.]\n",
      " [1.]\n",
      " [0.]\n",
      " [1.]\n",
      " [1.]\n",
      " [0.]]\n"
     ]
    }
   ],
   "source": [
    "threshold_predict = 0.03                       # decide on a cutoff limit\n",
    "y_pred_classes = np.zeros_like(pred_results)    # initialise a matrix full with zeros\n",
    "y_pred_classes[pred_results > threshold_predict] = 1       # add a 1 if the cutoff was breached\n",
    "y_test_classes = np.zeros_like(y_test)\n",
    "threshold_y_test = 0.2\n",
    "y_test_classes[y_test > threshold_y_test] = 1\n",
    "print('y_pred_classes: \\n ',y_pred_classes)\n",
    "print('y_test: \\n',y_test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "y_true and y_pred have different number of output (1!=150)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-21-33f74c87011c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"MSE: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_classes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_pred_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;31m#MSE:  0.12666666666666668\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\software\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36mmean_squared_error\u001b[1;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[0;32m    237\u001b[0m     \"\"\"\n\u001b[0;32m    238\u001b[0m     y_type, y_true, y_pred, multioutput = _check_reg_targets(\n\u001b[1;32m--> 239\u001b[1;33m         y_true, y_pred, multioutput)\n\u001b[0m\u001b[0;32m    240\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    241\u001b[0m     output_errors = np.average((y_true - y_pred) ** 2, axis=0,\n",
      "\u001b[1;32mD:\\Users\\software\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\regression.py\u001b[0m in \u001b[0;36m_check_reg_targets\u001b[1;34m(y_true, y_pred, multioutput)\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     86\u001b[0m         raise ValueError(\"y_true and y_pred have different number of output \"\n\u001b[1;32m---> 87\u001b[1;33m                          \"({0}!={1})\".format(y_true.shape[1], y_pred.shape[1]))\n\u001b[0m\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[0mn_outputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: y_true and y_pred have different number of output (1!=150)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "print(\"MSE: \",mean_squared_error(y_test_classes,y_pred_classes))\n",
    "#MSE:  0.12666666666666668"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'accuracy_score' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-d606a45da5b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;31m# predictionClasification=np.zeros(len(y_test_classes))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_pred_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0maccuracy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mprecision\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprecision_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mrecall\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrecall_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mzero_division\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# prediccionClasification=np.zeros(len(y_test_classes))\n",
    "thresholds=[]\n",
    "accuracy=[]\n",
    "precision=[]\n",
    "recall=[]\n",
    "f1=[]\n",
    "\n",
    "# predictionClasification=np.zeros(len(y_test_classes))\n",
    "for i in range(0, len(y_pred_classes)):\n",
    "    accuracy.append(accuracy_score(y_test_classes, y_pred_classes))\n",
    "    precision.append(precision_score(y_test_classes, y_pred_classes, zero_division=0))\n",
    "    recall.append(recall_score(y_test_classes, y_pred_classes, zero_division=0))\n",
    "    f1.append(f1_score(y_test_classes, y_pred_classes, zero_division=0))\n",
    "print('accuracy_score: ', accuracy_score(y_test_classes, y_pred_classes))\n",
    "print('precision_score: ', precision_score(y_test_classes, y_pred_classes, zero_division=0))\n",
    "print('recall_score: ', recall_score(y_test_classes, y_pred_classes, zero_division=0))\n",
    "print('f1_score: ', f1_score(y_test_classes, y_pred_classes, zero_division=0))\n",
    "#create precision recall curve\n",
    "from sklearn.metrics import auc, precision_recall_curve\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_classes, y_pred_classes)\n",
    "plt.figure(figsize = (10,8))\n",
    "plt.plot([0, 1], [0.5, 0.5],'--')\n",
    "plt.plot(recall, precision, label = 'Precision')\n",
    "plt.xlabel('recall')\n",
    "plt.ylabel('precision')\n",
    "plt.title('Recall-Precision-curve')\n",
    "plt.show()\n",
    "#accuracy_score:  0.8733333333333333\n",
    "#precision_score:  1.0\n",
    "#recall_score:  0.75\n",
    "#f1_score:  0.8571428571428571"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-44c486ece7ae>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprecision_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecall_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# cm=confusion_matrix(y_test,pred_results.ravel(),normalize=False)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mcm\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconfusion_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Confusion matrix: \\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Confusion matrix:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\software\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[1;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[0;32m    251\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    252\u001b[0m     \"\"\"\n\u001b[1;32m--> 253\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"binary\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"multiclass\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"%s is not supported\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\software\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score   \n",
    "# cm=confusion_matrix(y_test,pred_results.ravel(),normalize=False)\n",
    "cm=confusion_matrix(y_test_classes, y_pred_classes)\n",
    "print('Confusion matrix: \\n',cm)\n",
    "#Confusion matrix: \n",
    "# [[74  0]\n",
    "# [19 57]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(y_test_classes)\n",
    "# print('accuracy_score: ', accuracy_score(y_test_classes, y_pred_classes))\n",
    "# print('precision_score: ', precision_score(y_test_classes, y_pred_classes, zero_division=0))\n",
    "# print('recall_score: ', recall_score(y_test_classes, y_pred_classes, zero_division=0))\n",
    "# print('f1_score: ', f1_score(y_test_classes, y_pred_classes, zero_division=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-be4b85a1a6c4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcm\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mannot\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinewidths\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinecolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"red\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfmt\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\".0f\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0max\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"pred_results\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y_test\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cm' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#confusion matrix visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "f, ax=plt.subplots(figsize=(5,5))\n",
    "sns.heatmap(cm,annot=True,linewidths=0.5,linecolor=\"red\",fmt=\".0f\",ax=ax)\n",
    "plt.xlabel(\"pred_results\")\n",
    "plt.ylabel(\"y_test\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Classification metrics can't handle a mix of binary and multilabel-indicator targets",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-e36310787176>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Classification report: \\n'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mD:\\Users\\software\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[1;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict)\u001b[0m\n\u001b[0;32m   1522\u001b[0m     \"\"\"\n\u001b[0;32m   1523\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1524\u001b[1;33m     \u001b[0my_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1525\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1526\u001b[0m     \u001b[0mlabels_given\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\software\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[1;34m(y_true, y_pred)\u001b[0m\n\u001b[0;32m     79\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     80\u001b[0m         raise ValueError(\"Classification metrics can't handle a mix of {0} \"\n\u001b[1;32m---> 81\u001b[1;33m                          \"and {1} targets\".format(type_true, type_pred))\n\u001b[0m\u001b[0;32m     82\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[1;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Classification metrics can't handle a mix of binary and multilabel-indicator targets"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print('Classification report: \\n',classification_report(y_test_classes, y_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.875"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "auc_roc=metrics.roc_auc_score(y_test_classes, y_pred_classes)\n",
    "auc_roc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "bad input shape (150, 150)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-2da193bbb1f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mroc_curve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred_classes\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mroc_auc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mauc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\software\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36mroc_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[0;32m    616\u001b[0m     \"\"\"\n\u001b[0;32m    617\u001b[0m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[1;32m--> 618\u001b[1;33m         y_true, y_score, pos_label=pos_label, sample_weight=sample_weight)\n\u001b[0m\u001b[0;32m    619\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    620\u001b[0m     \u001b[1;31m# Attempt to drop thresholds corresponding to points in between and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\software\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[1;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[0;32m    399\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[0my_true\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 401\u001b[1;33m     \u001b[0my_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    402\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m     \u001b[0massert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_score\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Users\\software\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[1;34m(y, warn)\u001b[0m\n\u001b[0;32m    795\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m     \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"bad input shape {0}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: bad input shape (150, 150)"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_test_classes, y_pred_classes)\n",
    "roc_auc = auc(false_positive_rate, true_positive_rate)\n",
    "roc_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'false_positive_rate' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-87711cd37f86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'Receiver Operating Characteristic'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfalse_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtrue_positive_rate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'red'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlabel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'AUC = %0.2f'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'lower right'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlinestyle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'--'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'false_positive_rate' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(5,5))\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.plot(false_positive_rate,true_positive_rate, color='red',label = 'AUC = %0.2f' % roc_auc)\n",
    "plt.legend(loc = 'lower right')\n",
    "plt.plot([0, 1], [0, 1],linestyle='--')\n",
    "plt.axis('tight')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.xlabel('False Positive Rate')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
